{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"ğŸš€ Initialisation (Mode Nettoyage & RÃ©paration)...\")\n",
        "\n",
        "# --- 1. NETTOYAGE PRÃ‰ALABLE ---\n",
        "# On supprime les anciens dossiers pour Ã©viter les conflits\n",
        "if os.path.exists('flower_photos'):\n",
        "    shutil.rmtree('flower_photos')\n",
        "    print(\"ğŸ§¹ Anciens fichiers supprimÃ©s.\")\n",
        "\n",
        "# --- 2. TÃ‰LÃ‰CHARGEMENT MANUEL (WGET) ---\n",
        "# On tÃ©lÃ©charge directement Ã  la racine\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
        "# On dÃ©compresse\n",
        "!tar -xzf flower_photos.tgz\n",
        "\n",
        "# On dÃ©finit le dossier cible\n",
        "data_dir = 'flower_photos'\n",
        "\n",
        "# --- 3. VÃ‰RIFICATION CRUCIALE ---\n",
        "# On regarde ce qu'il y a dedans. On DOIT voir : daisy, dandelion, roses, etc.\n",
        "contenu = os.listdir(data_dir)\n",
        "print(f\"ğŸ§ CONTENU DU DOSSIER : {contenu}\")\n",
        "\n",
        "if 'roses' not in contenu:\n",
        "    raise ValueError(\"ERREUR : Les dossiers de fleurs sont introuvables !\")\n",
        "else:\n",
        "    print(\"âœ… Structure des dossiers VALIDÃ‰E (5 Classes trouvÃ©es) !\")\n",
        "\n",
        "# --- 4. PRÃ‰PARATION ---\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# On charge les donnÃ©es\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(160, 160),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse', # Mode multi-classes robuste\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(160, 160),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# --- 5. MODÃˆLE ---\n",
        "base_model = MobileNetV2(input_shape=(160, 160, 3),\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(5, activation='softmax')(x) # 5 Classes obligatoires\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# --- 6. ENTRAÃNEMENT ---\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"ğŸŒ» DÃ©marrage de l'entraÃ®nement...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "# --- 7. SAUVEGARDE ---\n",
        "model.save('agro_scan_model.h5')\n",
        "print(\"âœ… ModÃ¨le sauvegardÃ© sous 'agro_scan_model.h5'\")\n",
        "print(\"ğŸ‘‰ CLASSES FINALES :\", train_generator.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0VO9_2duIVH",
        "outputId": "b604e977-33d4-4aa8-bef5-d368d2df4ddd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Initialisation (Mode Nettoyage & RÃ©paration)...\n",
            "ğŸ§ CONTENU DU DOSSIER : ['sunflowers', 'roses', 'daisy', 'LICENSE.txt', 'dandelion', 'tulips']\n",
            "âœ… Structure des dossiers VALIDÃ‰E (5 Classes trouvÃ©es) !\n",
            "Found 2939 images belonging to 5 classes.\n",
            "Found 731 images belonging to 5 classes.\n",
            "ğŸŒ» DÃ©marrage de l'entraÃ®nement...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 486ms/step - accuracy: 0.3790 - loss: 1.5479 - val_accuracy: 0.6676 - val_loss: 0.8446\n",
            "Epoch 2/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 299ms/step - accuracy: 0.7122 - loss: 0.7972 - val_accuracy: 0.7729 - val_loss: 0.6405\n",
            "Epoch 3/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 286ms/step - accuracy: 0.7811 - loss: 0.6142 - val_accuracy: 0.7948 - val_loss: 0.5701\n",
            "Epoch 4/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 288ms/step - accuracy: 0.8107 - loss: 0.5331 - val_accuracy: 0.8112 - val_loss: 0.5288\n",
            "Epoch 5/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 288ms/step - accuracy: 0.8309 - loss: 0.4813 - val_accuracy: 0.8331 - val_loss: 0.4826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ModÃ¨le sauvegardÃ© sous 'agro_scan_model.h5'\n",
            "ğŸ‘‰ CLASSES FINALES : {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QwPx-tYc4PU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}